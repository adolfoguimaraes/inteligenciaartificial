{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYzSufRjVBn1"
      },
      "source": [
        "# Machine Learning - Análise de Sentimento.\n",
        "\n",
        "Para essa atividade vamos gerar uma modelo de análise de sentimento em inglês baseado em reviews retirados de 3 sites: Amazon, IMDb e Yelp. Essa base está disponível [neste link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). Mais detalhes podem ser encontrados no link ou no artigo de referência: *From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015*. \n",
        "\n",
        "A base possui um texto e para cada texto um sentimento sobre o conteúdo abordado no texto. Os sentimentos podem ser positivos (1) ou negativos (2). Foram coletados em média 500 textos para cada sentimento em cada base. \n",
        "\n",
        "Nesse notebook vamos construir uma modelo de aprendizagem para análise de sentimento em inglês. O primeiro passo foi carregar o Dataset de forma apropriada e em seguida construir a matriz de entrada para nosso algoritmo de Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvpLnvwqVBn9"
      },
      "source": [
        "## Carregando o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HyObzUCTGbqN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from joblib import dump, load\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YsQEgNvoVBn_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df_amazon = pd.read_csv(\"../datasets/analise_de_sentimento/amazon_cells_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_imdb = pd.read_csv(\"../datasets/analise_de_sentimento/imdb_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_yelp = pd.read_csv(\"../datasets/analise_de_sentimento/yelp_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "\n",
        "join_frames = [df_amazon, df_imdb, df_yelp]\n",
        "\n",
        "df_final_dataset = pd.concat(join_frames)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YCdoqw7-UsAE",
        "outputId": "6a401c25-ab58-49cb-b3f4-20431c9e1130"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2748 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  Sentiment\n",
              "0    So there is no way for me to plug it in here i...          0\n",
              "1                          Good case, Excellent value.          1\n",
              "2                               Great for the jawbone.          1\n",
              "3    Tied to charger for conversations lasting more...          0\n",
              "4                                    The mic is great.          1\n",
              "..                                                 ...        ...\n",
              "995  I think food should have flavor and texture an...          0\n",
              "996                           Appetite instantly gone.          0\n",
              "997  Overall I was not impressed and would not go b...          0\n",
              "998  The whole experience was underwhelming, and I ...          0\n",
              "999  Then, as if I hadn't wasted enough of my life ...          0\n",
              "\n",
              "[2748 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yxZHgMVBoD"
      },
      "source": [
        "## Construindo a base de dados\n",
        "\n",
        "A base de dados possui 2748 textos que foram classificados em dois sentimentos: negativo (0) e positivo (1). Construa uma base de dados apropriada para os testes. Divida a base em treino e teste (80% para treino e 20% para teste). A base de treinamento será utilizado para a construção do modelo e a de teste para o teste final do modelo construído. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RqzL23-qGXAq"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_final_dataset['Text'], \n",
        "                                                    df_final_dataset['Sentiment'], \n",
        "                                                    random_state=42,\n",
        "                                                    test_size=0.2\n",
        "                                                   )\n",
        "count_vector = CountVectorizer()\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "testing_data = count_vector.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-jDD96VBoS"
      },
      "source": [
        "## Treinando e Salvando um modelo de Machine Learning\n",
        "\n",
        "Nessa etapa vamos utilizar a biblioteca `scikit-learn` para treinar um modelo de Machine Learning. Em seguida vamos testar para ver a qualidade deste modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_oXYSFYHJZx"
      },
      "source": [
        "### Treinamento do Modelo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75B5x4kPVkbz",
        "outputId": "841d0fe5-37b8-4f9a-870a-748c1d4f3535"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(training_data, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-omy31iHMtN"
      },
      "source": [
        "### Teste do Modelo\n",
        "\n",
        "Nesse caso, estamos olhando somente para acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to9KqfovV7Z7",
        "outputId": "414bd036-e82f-4534-9907-2068a5fe5ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia de 79.45\n"
          ]
        }
      ],
      "source": [
        "acc_ = naive_bayes.score(testing_data, y_test)\n",
        "acc_str = \"Acurácia de %.2f\" % (acc_ * 100)\n",
        "print(acc_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vydX_HeBH1dd"
      },
      "source": [
        "### Testando o modelo treinado com uma frase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0ZXDq5Vz6c",
        "outputId": "be11b90c-81a9-4a05-d757-b5b85eb54a84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I dont't like that music\"\n",
        "predict_text = count_vector.transform([text])\n",
        "naive_bayes.predict(predict_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx3pxUKUIDkJ"
      },
      "source": [
        "### Treinando e salvando o modelo completo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVHPfvX_IPrM",
        "outputId": "f385c71e-ac2a-4222-85a9-2ad0d4e60eba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vector = CountVectorizer()\n",
        "final_data = count_vector.fit_transform(df_final_dataset['Text'])\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(final_data, df_final_dataset['Sentiment'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-AHkV-TIi9e"
      },
      "source": [
        "#### Salvando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFZQmD0oWaJ2",
        "outputId": "f296de5f-3e72-4884-be8e-6be891515246"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../output/model.joblib']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_ = {\n",
        "    'model': naive_bayes,\n",
        "    'vector': count_vector\n",
        "}\n",
        "dump(model_, \"../output/model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBBXB6kFIufM"
      },
      "source": [
        "#### Testando o modelo salvo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kHw_cRy3Ww5c"
      },
      "outputs": [],
      "source": [
        "loaded_model = load(\"../output/model.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj-Dp5yBW0X2",
        "outputId": "d8a700a0-cc53-44bd-f8b3-9e20d45635b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newtext = \"I love you my darling.\"\n",
        "ptext = loaded_model['vector'].transform([newtext])\n",
        "loaded_model['model'].predict(ptext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49D8309I7x7"
      },
      "source": [
        "O arquivo `model.joblib` vai ser carregado no bot para usar a funcionalidade de análise de sentimento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "10_MachineLearning_AnaliseDeSentimento.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
